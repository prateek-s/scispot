Transient cloud servers such as Amazon Spot instances, Google
Preemptible VMs, and Azure Low-priority batch VMs, can reduce cloud
computing costs by as much as $10\times$, but can be unilaterally
preempted by the cloud provider.  Understanding preemption
characteristics (such as frequency) is a key first step in minimizing
the effect of preemptions on application performance, availability,
and cost.  However, little is understood about \emph{temporally
  constrained} preemptions---wherein preemptions must occur in a given
time window.  We study temporally constrained preemptions by
conducting a large scale empirical study of Google's Preemptible VMs
(that have a \emph{maximum} lifetime of 24 hours), develop a new
preemption probability model, new model-driven resource management
policies, and implement them in a batch computing service for
scientific computing workloads.

Our statistical and experimental analysis indicates that temporally
constrained preemptions are \emph{not} uniformly distributed, but are
time-dependent and have a bathtub shape.  We find that existing
memoryless models and policies are not suitable for temporally
constrained preemptions.  We develop a new probability model for
bathtub preemptions, and analyze it through the lens of reliability
theory.  To highlight the effectiveness of our model, we develop
optimized policies for job scheduling and checkpointing.  Compared to
existing techniques, our model-based policies can reduce the
probability of job failure by more than $2\times$.  We also implement
our policies as part of a batch computing service for scientific
computing applications, which reduces cost by $5\times$ compared to
conventional cloud deployments and keeps performance overheads under
$3\%$.



% Our statistical analysis shows that preemptions are not uniformly distributed over the 24 hour interval, but instead 

% The rise in transient computing has led to the creation of many systems and techniques, that all depend on probabilistic modeling of preemptions in order to minimize their disruptive effects. 


% However, because Google's preemptible VMs have a maximum lifetime of 24 hours, existing models of preemptions are not applicable, and we lack fundamental understanding of preemptions and their impact on application behaviour and performance. 

% To model the unique, fixed lifetime of Preemptible VMs, we propose modeling techniques that are rooted in reliability theory and statistical mechanics.
% Proposed research is foundational and delivers the \emph{first} analytical model for preemption dynamics in Google Preemptible VMs.  
% Using the model-driven insights and mechanistic understanding, we develop optimized policies for cloud resource management and fault-tolerance, and implement them as part of a \emph{new} cloud-based software framework for running parallel scientific computing applications. 



%Although transient servers can be used to lower the costs of running scientific computing applications on the cloud, their frequent preemptions and resource heterogeneity makes their effective and efficient use challenging. 

%Our policies enable scientific computing applications to run
%

%SciSpot selects the appropriate transient cloud server for an application 
%of ``bags of jobs'' of scientific computing applications.  
%SciSpot's design is guided by our observation that most  scientific computing applications (such as simulations) are deployed as ``bag'' of jobs, which represent multiple instantiations of the same computation with different physical and computational parameters.
%SciSpot can 
%SciSpot reduces costs by $5\times$ compared to conventional cloud deployments, and makespans by up to $10\times$ compared to conventional HPC clusters.



%Treating bags of jobs as a unit of execution enables simple and powerful policies for optimizing the cost, makespan, and ease of deployment. 
%SciSpot uses Google Cloud Preemptible VMs, and provides the first empirical and analytical model for their preemptions. 
%SciSpot reduces costs by $5\times$ compared to conventional cloud deployments, and makespans by up to $10\times$ compared to conventional HPC clusters.


% We show that optimizing across an entire bag of jobs and being cognizant of the relation between different jobs in a bag, can enable simple and powerful policies for optimizing cost, makespan, and ease of deployment. 


% present SciSpot, a software framework for running scientific applications on transient cloud servers.


% Transient cloud servers can yield significantly lower costs compared to traditional on-demand cloud servers. 
% However, due to their preemptible nature and heterogeneity, their effective use remains challenging.
% %
% % 
% We perform a large-scale, first-of-its-kind empirical measurement and analytical modeling involving over a thousand Google preemptible VMs. 
% Our policies for tackling the resource heterogeneity and transient availability of cloud VMs build on a key insight: most scientific computing applications are deployed as ``bag'' of jobs, which represent multiple instantiations of the same computation with different parameters.
% SciSpot yields a cost saving of 70\% compared to traditional cloud deployments, and a makespan reduction of 20\% compared to a conventional HPC clusters. 

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
