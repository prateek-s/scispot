%\vspace*{\largesubsecspace}
\section{Introduction}
\label{sec:intro}
% Look, scientific applications are important, OK? And HPC. 

%Scientific computing applications play a critical role in understanding natural and synthetic phenomena associated with a wide range of material, biological, and engineering systems. 
%The computational models and simulations for analyzing these systems can consume a large amount of computing resources, and require access to large dedicated high performance computing (HPC) infrastructure. 



%such as supercomputers~\cite{bigred2}.


% VJ: perhaps it could be useful to point out that the cloud approach will not require any further code changes like one encounters in moving from sequential to MPI appraoch; but it would need a framework innovation

% But now we have the cloud!!1

Transient cloud computing is an emerging and popular resource allocation model used by all major cloud providers, and allows unused capacity to be offered at low costs as preemptible virtual machines.
Transient VMs can be unilaterally revoked and preempted by the cloud provider, and applications running inside them face fail-stop failures. 
Due to their volatile nature, transient VMs are offered at steeply discounted rates. Amazon EC2 spot instances~\cite{spot-documentation}, Google Cloud Preemptible VMs~\cite{preemptible-documentation}, and Azure Batch VMs~\cite{azure-batch}, are all examples of transient VMs, and are offered at discounts ranging from 50 to 90\% compared to conventional, non-preemptible ``on-demand'' VMs.


%
% Transient VMs are essentially surplus low-priority resources, and the frequency of preemptions is influenced by the availability of surplus resources and cloud operator's resource reclamation policies.
% Thus, preemptions are \emph{not} due to conventional hardware failures, and occur at higher rates. 
% From an application perspective however, preemptions are still akin to fail-stop failures, and cause application execution to be disrupted, leading to downtimes and performance degradation.



To expand the usability and appeal of transient VMs, many systems and techniques have been proposed that seek to ameliorate the effects of preemptions and reduce the computing costs of applications. 
%
Fault-tolerance mechanisms, resource management policies, and cost optimization techniques have been proposed for a wide range of applications---ranging from interactive web services, distributed data processing, parallel computing, etc.
%
These techniques have been shown to minimize the performance-degradation and downtimes due to preemptions, and reduce computing costs by up to 90\%. 


However, the success of these techniques depends on probabilistic estimates of when and how frequently preemptions occur. 
%the characteristics of the preemption rates. 
For instance, many fault-tolerance and resource optimization policies are parametrized by the mean time to failure (MTTF) of the transient VMs. 
For example, periodic checkpointing is a common technique for reducing the work lost due to preemptions, and the ``optimal'' checkpointing frequency that minimizes the total expected running time of a job depends on the MTTF of the VMs. 


%Inspite of the ubiquity of cloud transient VMs, to the best of our knowledge, all prior work has focused on Amazon's EC2 spot instances, whose preemptions are determined based on dynamic prices (that are in turn set using a continuous second-price auction). 

%Since transient VMs are essentially surplus low-priority resources, their frequency of preemptions is influenced by the availability of surplus resources and cloud operator's resource reclamation policies.



Past work on transient computing has focused on Amazon EC2's spot instances, whose preemption characteristics are determined by dynamic prices (which are in turn set using a continuous second-price auction). 
Transiency-mitigation techniques such as VM migration~\cite{spotcheck}, checkpointing~\cite{flint, marathe2014exploiting}, diversification~\cite{exosphere}, \emph{all} use price-signals to model the availability and preemption rates of spot instances. 
However, these pricing-based models are not generalizable to other transient VMs having a flat price (such as Google's or Azure's offerings).
In these cases, the lack of information about preemption characteristics precludes most failure modeling and transient computing optimizations. 


To address this gap, we seek to understand the preemption characteristics of Google's Preemptible VMs, whose distinguishing characteristic is that they have a \emph{maximum lifetime of 24 hours}. 
We conduct a large empirical study of over 1,500 preemptions of Google Preemptible VMs, and develop an analytical probability model of preemptions. 
We find that the temporal constraint is a radical departure from pricing-based preemptions, and presents fundamental challenges in preemption modeling and effective use of Preemptible VMs.


% XXX point to figure here? 

Due to the temporal preemption constraint, classical models that form the basis of preemption modeling and policies, such as memoryless exponential failure rates, are not applicable.
We find that preemption rates are \emph{not} uniform, but bathtub shaped with multiple distinct temporal phases, and are incapable of being modeled by existing bathtub distributions such as Weibull. 
We capture these characteristics by developing a new probability model. 
Our model uses reliability theory principles to capture the 24-hour lifetime of VMs, and generalizes to VMs of different resource capacities, geographical regions, and across different temporal domains. 
To the best of our knowledge, this is the \emph{first} work on constrained preemption modeling. 
%
Our investigation also points to a new, surprising connection to statistical mechanics, which can lead to new insights for modeling  temporally constrained events. 


We show the applicability and effectiveness of our model by developing optimized policies for job scheduling, checkpointing, and server selection. 
These policies are fundamentally dependent on empirical and analytical insights from our model such as different time-dependent failure rates of different types of VMs. 
These optimized policies are a building block for transient computing systems and reducing the performance degradation and costs of preemptible VMs. 
%and we show that the existing exponential ones are not suitable? 
We implement and evaluate these policies as part of a new software framework for running scientific computing applications, called \sysname.


\sysname abstracts typical scientific computing workloads and workflows into a new unit of execution, which we call as a ``bag of jobs''. 
These bags of jobs, ubiquitous in scientific computing, represent multiple instantiations of the same application launched with possibly different physical and computational parameters. 
The bag of jobs abstraction permits efficient implementation of our optimized policies, and allows \sysname to lower the costs and barriers of transient VMs for scientific computing applications.



Towards our goal of developing a better understanding of constrained preemptions, we make the following contributions:
%\vspace*{\largesubsecspace}
\begin{enumerate}[leftmargin=12pt]
% Yeah the "not spot" point below may need clarification before contribs
%\item Since transient server preemptions can disrupt the execution of jobs, we present the \emph{first} empirical model and analysis of transient server availability that is \emph{not} rooted in classical bidding models for EC2 spot instances that have been proposed thus far. Our empirical model allows us to predict expected running times and costs of different scientific computing applications.
\item We develop a probability model of constrained preemptions based on a large-scale, first-of-its-kind empirical study of lifetimes of Google Preemptible VMs for understanding and characterizing their preemption dynamics. 
  Our model captures the key effects resulting from the 24 hour lifetime constraint associated with these VMs, and we analyze it through the lens of reliability theory and statistical mechanics. 

%  and enables accurate prediction of expected running times and costs of different scientific computing applications.
% WTF is even partial redundancy? 

\item We develop optimized policies for job scheduling, periodic checkpointing, and VM selection, that minimize the total time and cost of running applications. These policies are based on our preemption models, and reduce job running times by up to 40\% compared to existing preemption models used for transient VMs. 
  
%\item In order to select the optimal VM for an application, from the plethora of choices offered by cloud providers, we develop a transient VM selection policy that minimizes the cost of running applications. Our search based policy selects a transient VM based on it's cost, performance, and preemption rate. 

\item We implement all our policies as part of a new framework, \sysname, and evaluate the cost and performance of different representative scientific computing  applications on the Google Cloud Platform. Compared to conventional cloud deployments, \sysname can reduce costs of running bags of jobs by more than $5\times$, and when compared to dedicated HPC clusters, it can reduce the total turnaround time by up to an order of magnitude. 

%\item Finally, ease of use and extensibility are one of the ``first principles'' in the design of \sysname, and we present the design and implementation of the system components and present case studies of how  scientific applications such as molecular dynamics simulations can be easily deployed on transient cloud VMs. 
\end{enumerate}



% Collectively, a bag of jobs can be used to ``sweep'' or search across a multi-dimensional parameter space to isolate the set of desired parameters associated with the scientific computation model. 
% Bags of jobs also help in the use of machine learning (ML) to enhance scientific computational methods ~\cite{ml.atomic2017,melko2017,sam2017,fu2017,long2015machine, ferguson2017machine,ward2018matminer}, when a collection of jobs with different  parameters  are launched to train and test ML models.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:

