Thanks to all reviewers for their detailed comments. We are glad that the the preemption data analysis and modeling was generally appreciated and are eager to share our dataset with the community. Below, we address concerns from each reviewer:

* Reviewer C and Reviewer A

- Restricted to current preemption dynamics. 

This is a valid concern that is applicable to /all/ work on transient computing. Our preemption model allows detecting policy and phase changes by comparing observed preemption data with the model, and opens the door for principled techniques for change-point detection. 
More broadly, the nature and specifics of preemption dynamics are at the mercy of the cloud provider, as is all other public-cloud-based research. 
However, changes are rare: Google's preemption policy has not changed since its inception in 2015. 



* Reviewer A

- Cost-model equation (item 3) 

For synchronous applications like MPI, a single preemption leads to application-failure and recomputation, which our model assumes. 

- Model never evaluated (items 4, 8)

We emphasize that the model is only for server selection, which we show in Figure 6 and 7, and only /relative/ expected turnaround times are actually necessary. Our design doesn't use the model for predicting exact times. 
Nevertheless, we will add a column in Table 1 with the model's estimate, and compare it with empirical running times. No new experiments will be required. Finally, a thorough evaluation of expected turnaround time requires running 1000s of jobs on different server types, and is beyond the scope of the current paper, but possible after SciSpot's increased adoption. 

- Item 7
Since D is deadline for the entire bag, parallelism = Deadline/Time-per-job, and the current equation holds. 

- Item 9 
Yes, last part of Section 6.1 should be read as expected recomputation time. 

- Item 10
::TODO::
Were these results obtained for different bags (launched at different times) leading to variability? For short (~2 hours) jobs like these, you expect variations in runtimes to the scale shown in Fig. 9 and 10 generally.


* Reviewer B

- Preemption data 

Figure 2 shows 100 *random* events out of 1500, for ease of exposition.
The bathtub shape is prevalent across all VM types and temporal domains (as shown in Figures 3 and 4), and our observations are robust against sampling biases. No experiment was run during known peak-load days. VM launch-times and other metadata will be part of our public dataset. 


- Need for bag-of-jobs

Bag of jobs allows server-selection cost to be amortized, which enables SciSpot to make better decisions concerning optional restarting of jobs based on the number of jobs submitted and completed (, and the cost evaluation?). /I think we should be more clear about the translation of bag of jobs benefits to SciSpot decision making abilities/
These benefits do not apply without this abstraction. 


- Experiment concerns (EC2-based models)

We implemented ExoSphere's policy (which assumes a non-constrained, EC2-like preemption dynamics) in SciSpot for a fair comparison, shown in Figure 7. 
We emphasize all EC2-spot based systems proposed thus far, are /not/ applicable, because they all assume historical pricing, exponentially distributed failures, and can't account for finite VM lifetimes. 
This can be seen from figure 2: the exponential distribution doesn't fit the data, and all EC2 systems have assumed that implicitly or explicitly.   

- " ExoSphere just does not know that larger VMs are better"

This is precisely why our sever selection is important. 


- Fig 6 and 10 dont say anything about SciSpot.

Figure 6 shows the importance of server selection (SciSpot selects the best server, as explained in the text; the caption can be enhanced based on this text). Figure 10 is important to show parallel scaling as practically many scientific computing applications are deployed on large clusters, but this figured can be removed if desired. 

- Use of ATLAS traces. 

Scientific workloads are run on HPC clusters, and we compare HPC waiting time vs. recomputation time, which is a very common concern in cloud-based scientific-computing. Our observations hold because of the large size and duration of ATLAS traces. We note that this is analogous to dozens of papers using (only) Google cluster traces. /I did not get the last sentence/

