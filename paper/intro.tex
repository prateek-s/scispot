\section{Introduction}

% Look, scientific applications are important, OK? And HPC. 

Scientific computing applications are a crucial component in the advancement of science and engineering, and play an important role in the analysis and processing of data, and understanding and modeling natural processes. 
These applications are typically implemented as large-scale parallel programs that use parallel-computing communication and coordination frameworks such as MPI.
To take advantage of their parallel nature, conventionally, these applications have mostly been deployed on large, dedicated high performance computing infrastructure such as super computers. 
%Logical flow here is not obvious and missing something. 


% But now we have the cloud!!1

Increasingly, cloud computing platforms have begun to supplement and complement conventional HPC infrastructure in order to meet the large computing and storage requirements of scientific applications. 
Public cloud platforms such as Amazon's EC2, Google Cloud Platform, and Microsoft Azure, offer multiple benefits such as \emph{on-demand} resource allocation, convenient pay-as-you-go pricing models, ease of provisioning and deployment, and near-instantaenous elastic scaling.
Most cloud platforms offer \emph{Infrastructure as a Service}, and provide computing resources in the form of \emph{Virtual Machines (VMs)}, on which a wide range of  applications such as web-services, distributed data processing, distributed machine learning, etc., are deployed. 
% a wide range of applications.

% Clouds are complex, and also have transience

In order to meet the diverse resource demands of different applications, public clouds offer resources (i.e., VM's) with multiple different resource configurations (such as number of CPU cores and memory capacity), and pricing and availability contracts. 
Conventionally, cloud VMs have been offered with ``on-demand'' availability, such that the lifetime of the VM was solely determined by the owner of the VM (i.e., the cloud customer). 
Increasingly however, cloud providers have begun offering VMs with \emph{transient}, rather than continuous on-demand availability. 
Transient VMs can be unilaterally revoked and preempted by the cloud provider, and applications running inside them face fail-stop failures. 
Due to their volatile nature, transient VMs are offered at steeply discounted rates. Amazon EC2 spot instances, Google Cloud Preemptible VMs, and Azure Batch VMs, are all examples of transient VMs, and are offered at discounts ranging from 50 to 90\%.  

% Very different from HPC and many challenges

However, deploying applications on cloud platforms presents multiple challenges due to the  \emph{fundamental} differences with conventional HPC clusters---which most applications still assume as their default execution environment.
%
While the on-demand resource provisioning and pay-as-you-go pricing makes it easy to spin-up computing clusters in the cloud, for effective resource utilization, the deployment of applications must be cognizant of the heterogeneity in VM sizes, pricing, and availability.
%
Although using transient resources can drastically reduce computing costs, 


% 

%Heterogeneity of the types of VMs and pricing models. Cost becomes important. 


%Public clouds can supplement and complement the supercomputing infrastructure. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Running parallel scientific applications, such as molecular dynamics (MD) simulations, on low-cost cloud transient resources. 

The first "big" idea is that simulations are often bag of parallel tasks. 

While there has been some past work that looks at running MPI applications on spot instances, our scope is much broader and considers how complete simulation pipelines can be run at low cost. 

Spiel on transient instances. Increasingly popular resource allocation model that is being offered by all cloud providers. 
Very low cost compared to conventional cloud resources, often by up to 10x. 
However, can be frequently revoked. 
Thus failure is a common occurrence, and not a rare-event. 
This is especially challenging for MPI jobs because of its inability to tolerate failures. 

However, our insight is that while protecting a *single* job against revocations can require elaborate checkpointing based approaches, we dont necessarily have to do that if we consider that most simulations are composed of a series of jobs that search over a parameter space, and that what is important is the total running time and cost of this entire series of jobs. 

Thus, no single job is "special". 

Another aspect of novelty is that past work on transient resources used EC2 pricing information to get failure probabilities. However, this is no longer an accurate method. We perform the first empirical study of google preemptible VMs and their performance and availability for HPC workloads. 

Another fundamental question is what is a suitable metric in such cases. Conventionally, it is speedup. In the cloud, it is some combination of cost and running time. 


\sysname is a framework and a tool that combines the use of failure modeling, checkpointing, and application-aware early stopping, to provide low cost execution of jobgroups for scientific applications.


Our work is the first to make a principled study of transient instances \emph{other} than Amazon spot instances.
Furthermore, our techniques make the first stab at addressing the new problems in the new EC2 spot pricing scheme.

Our work is in the context of reliability and cloud execution of scientific applications, and is novel because of multiple reasons:
1. Reliability and failure analysis of parallel scientific applications usually studied in the context of hardware with MTTFs of centuries, which is several orders of magnitudes higher than MTTFs faced in transient cloud servers (few hours).

2. While there have been studies of scientific applications been deployed in the context of cloud platforms, to the best of our knowledge, there has been no effort that integrates server selection and running jobgroups in a convenient automatic manner that makes it feasible to actually deploy applications on the cloud for scientists who may not have the requisite cloud experience.


\begin{comment}
Notes:
  
For scientific applications, public clouds offer many advantages such as no waiting/queuing time and instant access to a wide range of resources, and pay as you go pricing. 
However, judicious use of cloud resources is necessary to achieve high performance and to avoid cost overruns.

Increasingly, cloud providers are offering transient VMs that are sold at steeply discounted rates of 90\%.
However, they can be unilaterally revoked by the cloud provider, resulting in preemptions which are akin to fail-stop failures.
This is 


The inspiration for our work is the massively parallel molecular simulation pipelines that have been proposed recently that call for a large number of simulation parameters to be evaluated.
inspiration/case-study

Bag of jobs useful in many contexts. 


Easy to use and deploy tool that does not need special access to high performance computing systems. 

Cloud will be the key piece of software infrastructure for scientific applications.
However, the resource management and orchestration principles, techniques, and tools, are all different.
So in this paper, we design and develop mechanisms and policies for running these applications at \emph{low cost}.

Software framework.
Easy to run.
Auto-tuning and requires only specifying the program to run.
Auto-tunes resource allocation to minimize cost and running time.



Designing Materials to Revolutionize and Engineer ourFuture (DMREF) : Google cloud mention

CSSI: Robust service .
Framework implementation
 


\end{comment}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:

